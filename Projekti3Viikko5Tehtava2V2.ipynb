{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGpw0jrouK4m",
        "outputId": "2e20cad8-76e3-4216-d417-9e4c2d222790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Luokkien esiintymät:\n",
            " sensorvalue_d\n",
            "5.0    266\n",
            "6.0    242\n",
            "3.0    218\n",
            "2.0    217\n",
            "1.0    193\n",
            "4.0    189\n",
            "Name: count, dtype: int64\n",
            "x_train shape: (1060, 3)\n",
            "x_test shape: (265, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_16 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,694\u001b[0m (135.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,694</span> (135.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,694\u001b[0m (135.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,694</span> (135.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - accuracy: 0.2079 - loss: 1.7611 - val_accuracy: 0.1698 - val_loss: 1.6297\n",
            "Epoch 2/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3495 - loss: 1.6020 - val_accuracy: 0.8491 - val_loss: 1.4531\n",
            "Epoch 3/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 1.4191 - val_accuracy: 1.0000 - val_loss: 1.2262\n",
            "Epoch 4/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 1.1783 - val_accuracy: 1.0000 - val_loss: 0.9682\n",
            "Epoch 5/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.9224 - val_accuracy: 1.0000 - val_loss: 0.7023\n",
            "Epoch 6/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.6560 - val_accuracy: 1.0000 - val_loss: 0.4717\n",
            "Epoch 7/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4366 - val_accuracy: 1.0000 - val_loss: 0.2994\n",
            "Epoch 8/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2858 - val_accuracy: 1.0000 - val_loss: 0.1848\n",
            "Epoch 9/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1788 - val_accuracy: 1.0000 - val_loss: 0.1170\n",
            "Epoch 10/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1161 - val_accuracy: 1.0000 - val_loss: 0.0766\n",
            "Epoch 11/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0800 - val_accuracy: 1.0000 - val_loss: 0.0523\n",
            "Epoch 12/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0553 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
            "Epoch 13/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0417 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
            "Epoch 14/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
            "Epoch 15/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 1.0000 - val_loss: 0.0187\n",
            "Epoch 16/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
            "Epoch 17/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
            "Epoch 18/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
            "Epoch 19/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
            "Epoch 20/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
            "Test loss: 0.008538476191461086\n",
            "Test accuracy: 1.0\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00        48\n",
            "           2       1.00      1.00      1.00        48\n",
            "           3       1.00      1.00      1.00        32\n",
            "           4       1.00      1.00      1.00        54\n",
            "           5       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00       265\n",
            "   macro avg       1.00      1.00      1.00       265\n",
            "weighted avg       1.00      1.00      1.00       265\n",
            "\n",
            "Confusion Matrix:\n",
            " [[33  0  0  0  0  0]\n",
            " [ 0 48  0  0  0  0]\n",
            " [ 0  0 48  0  0  0]\n",
            " [ 0  0  0 32  0  0]\n",
            " [ 0  0  0  0 54  0]\n",
            " [ 0  0  0  0  0 50]]\n",
            "\n",
            "Painojen ja biasin 0 muoto: (3, 256)\n",
            "\n",
            "Painojen ja biasin 1 muoto: (256,)\n",
            "\n",
            "Painojen ja biasin 2 muoto: (256, 128)\n",
            "\n",
            "Painojen ja biasin 3 muoto: (128,)\n",
            "\n",
            "Painojen ja biasin 4 muoto: (128, 6)\n",
            "\n",
            "Painojen ja biasin 5 muoto: (6,)\n",
            "\n",
            "Input data shape: 3\n",
            "Input data scaled shape: 1\n",
            "\n",
            "Verkon ulostulo: (forward_propagation): [0.06353883172880984, 0.30032803248881074, 0.0904607869980191, 0.016374444719274878, 0.5126191267012203, 0.01667877736386511]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "\n",
            "Ennuste (model.predict): [[0.063529 0.300329 0.09045  0.01637  0.512649 0.016674]]\n",
            "\n",
            "Ero (absoluuttinen ero result ja prediction välillä):\n",
            "Ero 1: 0.00001003\n",
            "Ero 2: 0.00000088\n",
            "Ero 3: 0.00001097\n",
            "Ero 4: 0.00000489\n",
            "Ero 5: 0.00002999\n",
            "Ero 6: 0.00000495\n",
            "\n",
            "Keskimääräinen ero:  0.00001028\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras import layers, models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab import files\n",
        "import math\n",
        "import random\n",
        "\n",
        "# Ladataan data CSV-tiedostosta\n",
        "file_path = \"data_from_mysql_where_g160.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Tarkastetaan datan rakenne\n",
        "#print(data.head())\n",
        "\n",
        "# Suodatetaan pois kaikki rivit, joissa 'sensorvalue_d' on 0\n",
        "data_filtered = data[data['sensorvalue_d'] != 0]\n",
        "\n",
        "x_data = data_filtered[['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c']].values  # x, y, z\n",
        "y_data = data_filtered['sensorvalue_d'].values # suunta\n",
        "\n",
        "# Lasketaan luokkien esiintymät\n",
        "class_counts = data_filtered['sensorvalue_d'].value_counts()\n",
        "print(\"Luokkien esiintymät:\\n\", class_counts)\n",
        "\n",
        "# Skaalaus [0, 1] väliin ilman NumPy:n vektorilaskentaa\n",
        "def scale_to_unit_interval(data):\n",
        "    # Alustetaan listat minimi- ja maksimiarvoja varten\n",
        "    min_vals = [float('inf')] * len(data[0])  # Asetetaan alkuarvoksi \"ääretön\" jokaiselle sarakkeelle\n",
        "    max_vals = [float('-inf')] * len(data[0])  # Asetetaan alkuarvoksi \"-ääretön\" jokaiselle sarakkeelle\n",
        "\n",
        "    # Lasketaan minimi- ja maksimiarvot sarakkeittain\n",
        "    for row in data:\n",
        "        for col_idx, value in enumerate(row):\n",
        "            if value < min_vals[col_idx]:\n",
        "                min_vals[col_idx] = value\n",
        "            if value > max_vals[col_idx]:\n",
        "                max_vals[col_idx] = value\n",
        "\n",
        "    # Lasketaan skaalatut arvot\n",
        "    scaled_data = []\n",
        "    for row in data:\n",
        "        scaled_row = []\n",
        "        for col_idx, value in enumerate(row):\n",
        "            range_val = max_vals[col_idx] - min_vals[col_idx]\n",
        "            if range_val == 0:\n",
        "                range_val = 1  # Vältetään nollalla jakamista\n",
        "            scaled_value = (value - min_vals[col_idx]) / range_val\n",
        "            scaled_row.append(scaled_value)\n",
        "        scaled_data.append(scaled_row)\n",
        "\n",
        "    return scaled_data\n",
        "\n",
        "# Skaalataan syötteet\n",
        "x_data_scaled = scale_to_unit_interval(x_data)\n",
        "\n",
        "# Suuntaa on 6 luokkaa\n",
        "num_classes = 6\n",
        "y_data = keras.utils.to_categorical(y_data - 1, num_classes)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data_scaled, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"x_train shape: ({len(x_train)}, {len(x_train[0])})\")\n",
        "print(f\"x_test shape: ({len(x_test)}, {len(x_test[0])})\")\n",
        "\n",
        "# Muutetaan x_train ja x_test takaisin DataFrameiksi alkuperäisillä sarakenimillä\n",
        "x_train = pd.DataFrame(x_train, columns=['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c'])\n",
        "x_test = pd.DataFrame(x_test, columns=['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c'])\n",
        "\n",
        "# Funktio kohinan lisäämiseen\n",
        "def add_noise_to_data(df, columns, noise_factor=0.05):\n",
        "    noisy_df = df.copy()  # Säilytä alkuperäinen DataFrame\n",
        "    for column in columns:\n",
        "        std = df[column].std()\n",
        "        noise = [random.gauss(0, noise_factor * std) for _ in range(len(df))]  # Korvattu NumPy:lla\n",
        "        noisy_df[column] += noise  # Lisää kohina sarakkeeseen\n",
        "    return noisy_df\n",
        "\n",
        "# Lisää kohinaa harjoitus- ja testidataan\n",
        "x_train_noisy = add_noise_to_data(x_train, ['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c'])\n",
        "x_test_noisy = add_noise_to_data(x_test, ['sensorvalue_a', 'sensorvalue_b', 'sensorvalue_c'])\n",
        "\n",
        "# Määritellään malli\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(x_train_noisy.shape[1],)),  # Syötemuoto (x, y, z)\n",
        "        layers.Dense(64, activation=\"relu\"),  # Ensimmäinen tiheä kerros\n",
        "        layers.Dropout(0.2),  # Dropout, jotta ylikoulutus ei tapahdu\n",
        "        layers.Dense(32, activation=\"relu\"),  # Toinen tiheä kerros\n",
        "        layers.LeakyReLU(negative_slope=0.2),  # Vaihtoehto ReLU:lle\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),  # Lopullinen luokittelukerros\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Koulutetaan mallia\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train_noisy, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Arvioidaan malli testidatalla\n",
        "score = model.evaluate(x_test_noisy, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Tallennetaan malli (painot ja rakenne)\n",
        "model.save('my_model.keras')\n",
        "\n",
        "y_pred = model.predict(x_test_noisy)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_classes, y_pred_classes))\n",
        "print(\"\")\n",
        "\n",
        "# Osa 2\n",
        "\n",
        "# Haetaan mallin painot\n",
        "weights = model.get_weights()\n",
        "\n",
        "# Painot ovat lista, jossa on numpy-taulukoita\n",
        "for idx, weight in enumerate(weights):\n",
        "    print(f\"Painojen ja biasin {idx} muoto: {weight.shape}\")\n",
        "    print(\"\")\n",
        "    #print(f\"Painot ja bias {idx}:\", weight)\n",
        "\n",
        "# Aktivointifunktio ReLU\n",
        "def relu(x):\n",
        "    if isinstance(x, list):  # Jos x on lista\n",
        "        return [max(0, val) for val in x]\n",
        "    return max(0, x)  # Jos x on yksittäinen arvo\n",
        "\n",
        "# Aktivointifunktio Softmax\n",
        "def softmax(z):\n",
        "    exp_values = [2.718 ** i for i in z]  # Eksponenttiarvot\n",
        "    total = sum(exp_values)  # Lasketaan summan eksponentit\n",
        "    return [exp_value / total for exp_value in exp_values]  # Jaa eksponenttiarvot kokonaisuudella\n",
        "\n",
        "# Syöte\n",
        "for i in range(len(data_filtered)):\n",
        "    # Haetaan kunkin rivin arvot\n",
        "    x = data_filtered['sensorvalue_a'].values[i]\n",
        "    y = data_filtered['sensorvalue_b'].values[i]\n",
        "    z = data_filtered['sensorvalue_c'].values[i]\n",
        "\n",
        "    # Muutetaan syöte oikeaan muotoon\n",
        "    input_data = [x, y, z]\n",
        "\n",
        "#print(\"Input data shape:\", input_data.shape)\n",
        "print(\"Input data shape:\", len(input_data))\n",
        "\n",
        "# Skaalataan syöte\n",
        "input_data_scaled = scale_to_unit_interval([input_data])  # Muutetaan lista sisään\n",
        "\n",
        "print(\"Input data scaled shape:\", len(input_data_scaled))\n",
        "\n",
        "# Oikeat painot ja biasit\n",
        "weights_0, bias_0 = weights[0], weights[1]\n",
        "weights_1, bias_1 = weights[2], weights[3]\n",
        "weights_2, bias_2 = weights[4], weights[5]\n",
        "\n",
        "# Etenee syötteestä piilokerrosten kautta ulostuloon\n",
        "def forward_propagation(input_data_scaled):\n",
        "    # Piilokerros 1\n",
        "    z0 = []\n",
        "    for k in range(len(weights_0[0])):  # Käydään läpi piilokerroksen neuronit\n",
        "        z0_value = sum(input_data_scaled[0][i] * weights_0[i][k] for i in range(len(input_data_scaled[0]))) + bias_0[k]\n",
        "        z0.append(z0_value)\n",
        "    a0 = [relu(z) for z in z0]  # Aktivointi\n",
        "\n",
        "    # Piilokerros 2\n",
        "    z1 = []\n",
        "    for k in range(len(weights_1[0])):\n",
        "        z1_value = sum(a0[i] * weights_1[i][k] for i in range(len(a0))) + bias_1[k]\n",
        "        z1.append(z1_value)\n",
        "    a1 = [relu(z) for z in z1]  # Aktivointi\n",
        "\n",
        "    # Ulostulokerros\n",
        "    z2 = []\n",
        "    for k in range(len(weights_2[0])):  # Kolmannen kerroksen laskentaa (ulostulo)\n",
        "        z2_value = sum(a1[i] * weights_2[i][k] for i in range(len(a1))) + bias_2[k]\n",
        "        z2.append(z2_value)\n",
        "    output = softmax(z2)  # Softmax aktivointi\n",
        "\n",
        "    return output\n",
        "\n",
        "# Asetetaan NumPy:n tulostustapa niin, että ei käytetä tieteellistä merkintää\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "\n",
        "# Lasketaan tulos syötteelle (x, y, z)\n",
        "result = forward_propagation(input_data_scaled)\n",
        "print(\"\\nVerkon ulostulo: (forward_propagation):\", result)\n",
        "\n",
        "# Oikea syötemuoto model.predict\n",
        "input_data_scaled = scale_to_unit_interval([input_data])  # Muutetaan lista sisään\n",
        "\n",
        "# Varmistetaan, että syöte on oikeassa muodossa\n",
        "input_data_scaled = np.array(input_data_scaled)  # Muutetaan NumPy-taulukoksi\n",
        "input_data_scaled = input_data_scaled.reshape(1, -1)  # Muotoillaan se (1, 3) muotoon\n",
        "\n",
        "# Lasketaan ennuste koulutetulla mallilla\n",
        "prediction = model.predict(input_data_scaled)\n",
        "print(\"\\nEnnuste (model.predict):\", prediction)\n",
        "\n",
        "# Lasketaan ero tulosten välillä\n",
        "result = result  # Varmistetaan, että result on lista\n",
        "prediction = prediction[0].tolist()  # Muutetaan prediction listaksi\n",
        "\n",
        "# Lasketaan ero\n",
        "difference = [abs(r - p) for r, p in zip(result, prediction)]  # Lasketaan itseisarvoero\n",
        "\n",
        "# Tulostetaan ero desimaaleina ilman tieteellistä muotoa\n",
        "print(\"\\nEro (absoluuttinen ero result ja prediction välillä):\")\n",
        "for i, diff in enumerate(difference):\n",
        "    print(f\"Ero {i+1}: {diff:.8f}\")  # Tulostetaan desimaalimuodossa, pyöristettynä 8 desimaaliin\n",
        "\n",
        "# Keskimääräinen ero\n",
        "mean_difference = sum(difference) / len(difference)\n",
        "# Tulostetaan keskimääräinen ero desimaaleina ilman tieteellistä muotoa\n",
        "print(\"\\nKeskimääräinen ero: \", f\"{mean_difference:.8f}\")\n",
        "\n",
        "# Tallennetaan painot ja biasit header-tiedostoon\n",
        "header_file = \"neuroverkonKertoimet2.h\"\n",
        "\n",
        "with open(header_file, \"w\") as f:\n",
        "    f.write(\"#ifndef NEUROVERKONKERTOIMET_H\\n\")\n",
        "    f.write(\"#define NEUROVERKONKERTOIMET_H\\n\\n\")\n",
        "\n",
        "    # Kirjoitetaan painot ja biasit jokaiselle kerrokselle\n",
        "    for idx, weight in enumerate(weights):\n",
        "        if len(weight.shape) == 2:  # Painot (matriisi)\n",
        "            f.write(f\"float weights_{idx}[{weight.shape[0]}][{weight.shape[1]}] = {{\\n\")\n",
        "            for row in weight:\n",
        "                f.write(\"    {\" + \", \".join(map(str, row)) + \"},\\n\")\n",
        "            f.write(\"};\\n\\n\")\n",
        "        elif len(weight.shape) == 1:  # Bias (vektori)\n",
        "            f.write(f\"float biases_{idx}[{weight.shape[0]}] = {{\")\n",
        "            f.write(\", \".join(map(str, weight)))\n",
        "            f.write(\"};\\n\\n\")\n",
        "\n",
        "    f.write(\"#endif // NEUROVERKONKERTOIMET_H\\n\")"

      ]
    }
  ]
}
